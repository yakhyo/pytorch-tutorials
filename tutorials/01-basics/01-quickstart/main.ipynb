{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3b5f96-ad04-4e82-aa34-e000ff11111c",
   "metadata": {},
   "source": [
    "# QUICKSTART\n",
    "Into PyTorch Ecosystem\n",
    "\n",
    "## Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caaf8bb0-e13f-4d55-b47c-b48b5971f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5c3c3a-249e-4c40-9cbd-d95f6756d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d7838e-353f-46f0-8cea-bfadb1e0b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and prepare data\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e41bf5-40a6-40b8-a597-cefb26be1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data loaders\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1051a3a5-53dd-4e5a-b62c-0eaa870bb2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# check created data loader\n",
    "\n",
    "for images, labels in test_dataloader:\n",
    "    print('Shape of X [N, C, H, W]:', images.size())\n",
    "    print('Shape of y:', labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3273ec4-327e-46b8-acc7-72ca65385825",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "To define a neural network in PyTorch, we create a class that inherits from `nn.Module`. We define the layers of the network in the `__init__` function and specify how data will pass through the network in the forward function. To accelerate operations in the neural network, we move it to the GPU or MPS if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd9dbb5-976d-47d8-a8c1-d4065cb8c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# get cpu, gpu or mps device for training\n",
    "\n",
    "device = (\n",
    "    \"cuda\" \n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414bddd8-99f4-42db-baf6-0a5333a5b45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968b3bb5-7069-4d1e-9bd7-8970ec4002ff",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters\n",
    "\n",
    "To train a model, we need a loss function and an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1632d0-6629-424f-b301-3ff352b2a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss and optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a78809-38eb-40c5-8217-4cf72ed55682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training loop\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7967273-c7f3-4487-abd9-2e25786066ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define testing loop\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb0513b0-6ffd-4e27-a7ed-8a924ff62c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305141  [   64/60000]\n",
      "loss: 2.290028  [ 6464/60000]\n",
      "loss: 2.282212  [12864/60000]\n",
      "loss: 2.270439  [19264/60000]\n",
      "loss: 2.246906  [25664/60000]\n",
      "loss: 2.237699  [32064/60000]\n",
      "loss: 2.205321  [38464/60000]\n",
      "loss: 2.206088  [44864/60000]\n",
      "loss: 2.187150  [51264/60000]\n",
      "loss: 2.134756  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 48.8%, Avg loss: 2.151992 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.146928  [   64/60000]\n",
      "loss: 2.129657  [ 6464/60000]\n",
      "loss: 2.094079  [12864/60000]\n",
      "loss: 2.072794  [19264/60000]\n",
      "loss: 2.074192  [25664/60000]\n",
      "loss: 2.027647  [32064/60000]\n",
      "loss: 2.038347  [38464/60000]\n",
      "loss: 1.979303  [44864/60000]\n",
      "loss: 1.941553  [51264/60000]\n",
      "loss: 1.896438  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.0%, Avg loss: 1.878431 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.848538  [   64/60000]\n",
      "loss: 1.860489  [ 6464/60000]\n",
      "loss: 1.870645  [12864/60000]\n",
      "loss: 1.783836  [19264/60000]\n",
      "loss: 1.734758  [25664/60000]\n",
      "loss: 1.728753  [32064/60000]\n",
      "loss: 1.631994  [38464/60000]\n",
      "loss: 1.532592  [44864/60000]\n",
      "loss: 1.589875  [51264/60000]\n",
      "loss: 1.499275  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.516259 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.574905  [   64/60000]\n",
      "loss: 1.436851  [ 6464/60000]\n",
      "loss: 1.405708  [12864/60000]\n",
      "loss: 1.435074  [19264/60000]\n",
      "loss: 1.555503  [25664/60000]\n",
      "loss: 1.376565  [32064/60000]\n",
      "loss: 1.221160  [38464/60000]\n",
      "loss: 1.225801  [44864/60000]\n",
      "loss: 1.273212  [51264/60000]\n",
      "loss: 1.242173  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.0%, Avg loss: 1.251164 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.237858  [   64/60000]\n",
      "loss: 1.230853  [ 6464/60000]\n",
      "loss: 1.117301  [12864/60000]\n",
      "loss: 1.200455  [19264/60000]\n",
      "loss: 1.099730  [25664/60000]\n",
      "loss: 1.239955  [32064/60000]\n",
      "loss: 1.110333  [38464/60000]\n",
      "loss: 1.140432  [44864/60000]\n",
      "loss: 0.984907  [51264/60000]\n",
      "loss: 1.033401  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.086187 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# start training and testing process\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8e850-05f5-4b1d-85ec-78f11098ae12",
   "metadata": {},
   "source": [
    "## Saving Models\n",
    "\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a1d568-9935-4438-9fdd-fca36f138d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7142d-18a4-4f52-87ca-1588d5481fbf",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "\n",
    "The process for loading a model includes re-creating the model structure and loading the state dictionary into it.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52672efd-0ae8-424b-a1c1-2ee5d6cf14f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved model\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23e92da-5457-4a99-b451-2db364aa5d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "# make some predictions\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840e552-a62c-4afd-bb07-71a8b7d4273e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
